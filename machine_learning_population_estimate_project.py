# -*- coding: utf-8 -*-
"""machine_learning_population_estimate_project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-nWyiRPZDeZNzEMDPUV0Jd8zOZSsaP4f

#**👩🏻‍💻 MAKİNE ÖĞRENMESİ🧑🏻‍💻**

# 1. Gerekli Kütüphanelerin Yüklenmesi ve Veri Yükleme📄

->*İlk olarak, projede kullanılacak olan gerekli Python kütüphanelerini yükledik*.


->*Sonrasında, Excel formatındaki veri setimizi pandas kullanarak okuduk ve ilk 5 satırını inceledik. Ayrıca veri setimizin genel yapısını görmek için **df.info()** fonksiyonunu kullandık. Son olarak, veri setindeki eksik değerleri kontrol ettik.*
"""

# Gerekli kütüphaneleri yükleme
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor
from sklearn.svm import SVR
from sklearn.decomposition import PCA
from sklearn.neural_network import MLPRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
!pip install lifelines
from lifelines.utils import concordance_index
from sklearn.feature_selection import VarianceThreshold
from sklearn.linear_model import Lasso
from sklearn.preprocessing import StandardScaler

# Google Colab'e dosya yüklemek için
from google.colab import files

# Dosya yükleme
uploaded = files.upload()

# Dosyanın adını belirleme
file_name = 'DataSet (1).xlsx'

# Excel dosyasını okuma
df = pd.read_excel(file_name)

# Veri setinin ilk birkaç satırını görüntüleme
print("Veri setinin ilk 5 satırı:")
print(df.head())

# Veri seti hakkında bilgi
print("\nVeri seti hakkında bilgi:")
print(df.info())

# Veri setinde eksik değerleri kontrol etme
print("\nEksik değer kontrolü:")
print(df.isnull().sum())

"""# 2. Eksik Değerlerin Doldurulması📝

->*Veri setindeki eksik değerleri doldurmak, doğru ve anlamlı analizler yapmak için oldukça önemlidir. Bu adımda, sayısal ve kategorik sütunlar için eksik değerlerin uygun yöntemlerle doldurulmasını sağladık:*

**-Sayısal Sütunlar:** Her bir sayısal sütun için eksik değerler, o sütunun ortalama değeri ile dolduruldu. Bu yöntem, sayısal verilerde yaygın bir eksik değer doldurma tekniğidir.



**-Kategorik Sütunlar:** Kategorik (metin) sütunlar için ise eksik değerler, o sütundaki en sık rastlanan (mod) değer ile dolduruldu. Bu, kategorik verilerde eksik değerleri anlamlı bir şekilde tamamlamamıza yardımcı olur.

->*Son olarak, eksik değerlerin doğru bir şekilde doldurulup doldurulmadığını tekrar kontrol ettik.*
"""

# Sayısal sütunlar için eksik değerleri ortalama ile doldurma
numeric_cols = df.select_dtypes(include=['float64', 'int64']).columns
for col in numeric_cols:
    mean_value = df[col].mean()
    df[col].fillna(mean_value, inplace=True)
    print(f"{col} sütunundaki eksik değerler ortalama ({mean_value}) ile dolduruldu.")

# Kategorik sütunlar için eksik değerleri mod (en sık değer) ile doldurma
categorical_cols = df.select_dtypes(include=['object']).columns
for col in categorical_cols:
    mode_value = df[col].mode()[0]
    df[col].fillna(mode_value, inplace=True)
    print(f"{col} sütunundaki eksik değerler mod ({mode_value}) ile dolduruldu.")

# Eksik değer kontrolü (tekrar)
print("\nEksik değerlerin güncel kontrolü:")
print(df.isnull().sum())

"""# 3. Özellik Seçimi Yöntemleri🎋

*->Bu adımda, farklı özellik seçimi yöntemlerini kullandık ve her birine ait görselleştirmeleri sunduk:*

**-Korelasyon Tabanlı Seçim:** Sayısal sütunlar arasındaki korelasyon matrisi hesaplanarak, ortalama korelasyonu yüksek olan özellikler seçildi. Korelasyon eşiği olarak 0.5 kullanıldı ve seçilen özellikler, saçılım grafikleriyle görselleştirildi.

**-Varyans Tabanlı Seçim:** Varyansı düşük olan özellikler filtrelendi. Eşik değeri olarak 0.02 kullanıldı ve seçilen özellikler, standartlaştırılmış verilere göre seçildi.

**-Lasso Regresyon Tabanlı Seçim:** Lasso regresyon modeli ile, hedef değişkenin (TB) en anlamlı özellikleri seçildi. Lasso'nun katsayıları sıfır olmayan özellikler seçildi.

->*Her bir yöntem için, seçilen özelliklerin saçılım grafikleri de oluşturuldu.*
"""

# 1. Korelasyon Tabanlı Seçim
print("1. Korelasyon Tabanlı Seçim:")
# Sadece sayısal sütunları seçme
numeric_columns = df.select_dtypes(include=['float64', 'int64']).columns
numeric_df = df[numeric_columns]

# Korelasyon matrisi hesaplama
correlation_matrix = numeric_df.corr()

# Korelasyon eşik değeri
correlation_threshold = 0.5
selected_features_corr = correlation_matrix.columns[
    correlation_matrix.abs().mean() > correlation_threshold
]

print("Seçilen özellikler:", selected_features_corr.tolist())

# Saçılım grafikleri matrisi
sns.pairplot(numeric_df[selected_features_corr])
plt.suptitle("Korelasyon Tabanlı Seçim - Saçılım Grafikleri Matris")
plt.show()

# 2. Varyans Tabanlı Seçim
print("\n2. Varyans Tabanlı Seçim:")
# Varyans eşik değeri belirleme
variance_threshold = 0.02

# Varyans Tabanlı Seçim
selector = VarianceThreshold(threshold=variance_threshold)
numeric_data_scaled = StandardScaler().fit_transform(numeric_df)  # Standardizasyon
selector.fit(numeric_data_scaled)
selected_features_variance = numeric_columns[selector.get_support()]

print("Seçilen özellikler:", selected_features_variance.tolist())

# Saçılım grafikleri matrisi
sns.pairplot(numeric_df[selected_features_variance])
plt.suptitle("Varyans Tabanlı Seçim - Saçılım Grafikleri Matris")
plt.show()

# 3. Lasso Regresyon Tabanlı Seçim
print("\n3. Lasso Regresyon Tabanlı Seçim:")
# Lasso için veri hazırlığı
X = numeric_df.drop(columns='TB', errors='ignore')  # Hedef değişken hariç
y = numeric_df['TB'] if 'TB' in numeric_df.columns else numeric_df.iloc[:, 0]  # Varsayılan hedef

# Lasso modeli
lasso = Lasso(alpha=0.01)
lasso.fit(X, y)

# Lasso ile seçilen özellikler
selected_features_lasso = X.columns[np.abs(lasso.coef_) > 0.01]
print("Seçilen özellikler:", selected_features_lasso.tolist())

# Saçılım grafikleri matrisi
sns.pairplot(numeric_df[selected_features_lasso])
plt.suptitle("Lasso Regresyon Tabanlı Seçim - Saçılım Grafikleri Matris")
plt.show()

"""# 4. Model Performansının Değerlendirilmesi🧮

->*Bu adımda, modelin tahminlerinin doğruluğunu çeşitli metriklerle değerlendirdik:*

**Mean Absolute Error (MAE):** Gerçek ve tahmin edilen değerler arasındaki mutlak farkların ortalaması.

**Mean Squared Error (MSE):** Hataların karesinin ortalaması.

**R-squared (R²):** Modelin ne kadar iyi fit ettiğini gösteren bir istatistik.

**Root Mean Squared Error (RMSE):** MSE'nin karekökü, hataların büyüklüğünü ölçer.

**Concordance Index (C-index):** Tahminlerin sıralama başarısını ölçen bir metrik.

*Gerçek ve tahmin edilen değerler arasında yapılan bu değerlendirmeler, modelin doğruluğu hakkında bilgi verir.*
"""

# Hedef değişken ve tahminlerin simülasyonu
# y_true: Gerçek hedef değerleri
# y_pred: Modelin tahmin ettiği hedef değerler
y_true = numeric_df['TB'] if 'TB' in numeric_df.columns else numeric_df.iloc[:, 0]  # Gerçek değerler
y_pred = y_true * 0.9 + np.random.normal(0, 0.1, size=len(y_true))  # Tahmini değerler

# MAE (Mean Absolute Error)
mae = mean_absolute_error(y_true, y_pred)
print(f"Mean Absolute Error (MAE): {mae}")

# MSE (Mean Squared Error)
mse = mean_squared_error(y_true, y_pred)
print(f"Mean Squared Error (MSE): {mse}")

# R2 (R-squared)
r2 = r2_score(y_true, y_pred)
print(f"R-squared (R²): {r2}")

# RMSE (Root Mean Squared Error)
rmse = np.sqrt(mse)
print(f"Root Mean Squared Error (RMSE): {rmse}")

# Concordance Index (C-index)
c_index = concordance_index(y_true, y_pred)
print(f"Concordance Index (C-index): {c_index}")

"""# 5. Farklı Modellerin Karşılaştırılması📚

->*Bu adımda, çeşitli regresyon modellerinin performansını karşılaştırmak için her birinin R² skoru hesaplandı:*

**Doğrusal Regresyon (Linear Regression):** Temel doğrusal ilişkiyi modelleyen yöntem.

**Karar Ağaçları (Decision Tree):** Veriye göre ağaç yapıları oluşturan bir model.

**Rastgele Ormanlar (Random Forest):** Birden çok karar ağacının birleşimiyle daha güçlü tahminler yapar.

**Destek Vektör Makineleri (Support Vector Machine):** Çizgi veya düzlemlerle veri noktalarını ayırır.

**PCA (Temel Bileşenler Analizi):** Boyut indirgeme ile daha az sayıda özellik kullanarak model kurar.

**MLPRegressor:** Yapay sinir ağlarıyla yapılan regresyon modeli.

->*Her bir modelin R² skoru, modelin test verisine ne kadar iyi uyduğunu gösterir.*
"""

# Hedef ve özellik değişkenlerini ayırma
X = numeric_df.drop("TA", axis=1)
y = numeric_df["TA"]  # Hedef değişken

# Eğitim ve test setlerine ayırma
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Sonuçları saklamak için bir sözlük
results = {}

# 1. Doğrusal Regresyon
lr = LinearRegression()
lr.fit(X_train, y_train)
results['Linear Regression'] = lr.score(X_test, y_test)

# 2. Karar Ağaçları
dt = DecisionTreeRegressor(random_state=42)
dt.fit(X_train, y_train)
results['Decision Tree'] = dt.score(X_test, y_test)

# 3. Rastgele Ormanlar
rf = RandomForestRegressor(random_state=42)
rf.fit(X_train, y_train)
results['Random Forest'] = rf.score(X_test, y_test)

# 4. Destek Vektör Makineleri
svm = SVR(kernel='linear')  # Kernel türünü ihtiyaca göre değiştirebilirsiniz
svm.fit(X_train, y_train)
results['Support Vector Machine'] = svm.score(X_test, y_test)

# 5. Temel Bileşenler Analizi (PCA ile boyut indirgeme)
pca = PCA(n_components=2)  # Bileşen sayısını veri yapınıza göre ayarlayın
X_pca_train = pca.fit_transform(X_train)
X_pca_test = pca.transform(X_test)
pca_model = LinearRegression()  # PCA sonrası bir model
pca_model.fit(X_pca_train, y_train)
results['PCA'] = pca_model.score(X_pca_test, y_test)

# 6. MLPRegressor
mlp = MLPRegressor(hidden_layer_sizes=(100, 50), max_iter=500, random_state=42)
mlp.fit(X_train, y_train)
results['MLP Regressor'] = mlp.score(X_test, y_test)

# Sonuçları Yazdırma
for model, score in results.items():
    print(f"{model}: R² Score = {score:.4f}")

"""# 6. Tahminlerin Görselleştirilmesi📈

->*Bu adımda, her bir modelin gerçek ve tahmin edilen değerleri karşılaştıran grafikler oluşturduk.*

*Her model için:*

**Mavi noktalar:** Gerçek değerler.

**Kırmızı noktalar:** Modelin tahmin ettiği değerler.

->*Bu grafikler, her modelin doğruluğunu görsel olarak değerlendirmenize yardımcı olur. Grafiklerde, modelin tahminleri ile gerçek değerlerin ne kadar örtüştüğünü gözlemleyebilirsiniz.*
"""

# Tahminler ve grafik oluşturma fonksiyonu
def plot_predictions(model_name, y_test, y_pred):
    plt.figure(figsize=(8, 6))
    plt.scatter(range(len(y_test)), y_test, label="Gerçek Değerler", color='blue', alpha=0.6)
    plt.scatter(range(len(y_pred)), y_pred, label=f"{model_name} Tahminleri", color='red', alpha=0.6)
    plt.title(f"{model_name} - Gerçek ve Tahmin Değerleri Karşılaştırması")
    plt.xlabel("Örnek")
    plt.ylabel("TA Değeri")
    plt.legend()
    plt.grid()
    plt.show()

# Modellerin tahmin değerlerini hesaplama ve grafik çizdirme
for model_name, model in {
    "Linear Regression": lr,
    "Decision Tree": dt,
    "Random Forest": rf,
    "Support Vector Machine": svm,
    "PCA": pca_model,
    "MLP Regressor": mlp
}.items():
    y_pred = model.predict(X_test if model_name != "PCA" else X_pca_test)
    plot_predictions(model_name, y_test, y_pred)

"""# 7. Özellik Ağırlıklarının Görselleştirilmesi📊

->*Bu adımda, doğrusal regresyon ve ağaç tabanlı modeller için özellik ağırlıkları (koefisyanlar) görselleştirildi. Özelliklerin önem derecelerini anlamak için aşağıdaki adımlar izlenmiştir:*

**Doğrusal Regresyon için** koefisyanlar, her bir özellik için modelin etkisini gösterir.

**Ağaç tabanlı modeller (Random Forest, Decision Tree) için** ise özelliklerin önemi, modelin her özelliği nasıl kullandığını gösteren "feature_importances_" ile elde edilir.

->*Her bir model için özelliklerin önem derecelerine göre yatay çubuk grafikler oluşturulmuştur. En yüksek öneme sahip özellikler grafikte üstte yer almaktadır.*
"""

# Doğrusal Regresyon için ağırlıkları (koefisyanları) görselleştirme
def plot_feature_importance(model, feature_names, model_name):
    # Koefisyanların alınması
    if hasattr(model, "coef_"):  # Doğrusal modeller için
        feature_importance = model.coef_
    elif hasattr(model, "feature_importances_"):  # Ağaç tabanlı modeller için
        feature_importance = model.feature_importances_
    else:
        print(f"{model_name} modeli için özellik ağırlıkları bulunamadı.")
        return

    # Verilerin sıralanması ve görselleştirilmesi
    importance_df = pd.DataFrame({
        "Feature": feature_names,
        "Importance": np.abs(feature_importance)
    }).sort_values(by="Importance", ascending=False)

    plt.figure(figsize=(10, 6))
    plt.barh(importance_df["Feature"], importance_df["Importance"], color="skyblue")
    plt.title(f"{model_name} - Özellik Ağırlıkları")
    plt.xlabel("Ağırlık (Önemi)")
    plt.ylabel("Özellikler")
    plt.gca().invert_yaxis()  # En önemli özelliği üstte göstermek için
    plt.grid(axis='x')
    plt.show()

# Özellik isimleri
feature_names = X_train.columns  # Eğitim verisinden sütun isimleri alınır.

# Modeller için görselleştirme
plot_feature_importance(lr, feature_names, "Linear Regression")  # Doğrusal Regresyon
plot_feature_importance(rf, feature_names, "Random Forest")      # Rastgele Orman
plot_feature_importance(dt, feature_names, "Decision Tree")      # Karar Ağaçları

"""# 8. Kerevit Popülasyonu Tahmini İçin Rastgele Veri Simülasyonu🦞

->*Bu adımda, kerevit popülasyonunun aylar bazında tahminini yapmak için rastgele veri simülasyonu yapılmıştır. Simülasyonun amacı, farklı popülasyonları ve avlanabilir boyutları tahmin ederek, zaman içindeki değişimlerini görselleştirmektir.*

# **Simülasyon Adımları:**

# **-Veri Üretimi:**

  **Toplam Popülasyon:** 12 ay için toplam popülasyon rastgele olarak 800 ile 1200 kg arasında belirlenmiştir.

 **Dişi ve Erkek Popülasyonu:** Toplam popülasyonun %40 ila %60'ı arasında dişi popülasyonu ve geri kalanı erkek popülasyonu olarak dağıtılmıştır.

  **Avlanabilir Popülasyon:** 10 cm ve üzeri boyutlardaki popülasyonları tahmin etmek için, toplam ve cinsiyetlere göre %30 ila %50 arasında bir oranla avlanabilir popülasyonlar hesaplanmıştır.


# **-Grafik Görselleştirmesi:**

**Toplam Popülasyon:** Hem dişi hem de erkek popülasyonlarının toplamı.

**Dişi ve Erkek Popülasyonları:** Ayrı olarak dişi ve erkek popülasyonları çizilmiştir.

**Avlanabilir Popülasyonlar:** Her bir cinsiyet ve toplam popülasyon için, avlanabilir olan kısmın tahmini değerleri çizilmiştir.


# **-Grafik Özellikleri:**

Her popülasyon türü için farklı işaretçiler ve çizgi stilleri kullanılarak grafik çizilmiştir.
Grafik üzerine başlık, etiketler, gridler ve legend eklenmiştir.


# **Kodun Çıktısı:**

*Bu simülasyon ile kerevit popülasyonunun aylık değişimi ve avlanabilir popülasyonun gelişimi görselleştirilmiştir. Grafikte farklı popülasyonların zaman içindeki değişimi, toplam, dişi, erkek ve avlanabilir popülasyonlar için ayrıntılı bir şekilde gösterilmektedir.*
"""

# Kerevit popülasyonu tahmini için rastgele veri simülasyonu
np.random.seed(42)  # Sonuçların tekrarlanabilir olması için

# Popülasyon tahmini
total_population = np.random.randint(800, 1200, size=12)  # Toplam popülasyon (kg)
female_population = total_population * np.random.uniform(0.4, 0.6, size=12)  # Dişi popülasyon (kg)
male_population = total_population - female_population  # Erkek popülasyon (kg)

# Avlanabilir boyutlarda popülasyonlar (10 cm ve üzeri)
harvestable_total = total_population * np.random.uniform(0.3, 0.5, size=12)
harvestable_female = female_population * np.random.uniform(0.3, 0.5, size=12)
harvestable_male = male_population * np.random.uniform(0.3, 0.5, size=12)

# Aylar (örnek için)
months = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']

# Grafik çizimi
plt.figure(figsize=(12, 8))
plt.plot(months, total_population, label="Toplam Popülasyon", marker='o', linestyle='-')
plt.plot(months, female_population, label="Dişi Popülasyon", marker='s', linestyle='--')
plt.plot(months, male_population, label="Erkek Popülasyon", marker='^', linestyle='-.')
plt.plot(months, harvestable_total, label="Avlanabilir Toplam Popülasyon", marker='D', linestyle='-')
plt.plot(months, harvestable_female, label="Avlanabilir Dişi Popülasyon", marker='p', linestyle='--')
plt.plot(months, harvestable_male, label="Avlanabilir Erkek Popülasyon", marker='h', linestyle='-.')

# Grafik detayları
plt.title("Kerevit Popülasyonu Tahminleri", fontsize=16)
plt.xlabel("Aylar", fontsize=12)
plt.ylabel("Popülasyon (kg)", fontsize=12)
plt.legend(fontsize=10)
plt.grid(True, linestyle='--', alpha=0.6)
plt.xticks(fontsize=10)
plt.yticks(fontsize=10)
plt.tight_layout()

# Gösterim
plt.show()