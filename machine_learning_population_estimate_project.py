# -*- coding: utf-8 -*-
"""machine_learning_population_estimate_project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-nWyiRPZDeZNzEMDPUV0Jd8zOZSsaP4f

#**ğŸ‘©ğŸ»â€ğŸ’» MAKÄ°NE Ã–ÄRENMESÄ°ğŸ§‘ğŸ»â€ğŸ’»**

# 1. Gerekli KÃ¼tÃ¼phanelerin YÃ¼klenmesi ve Veri YÃ¼klemeğŸ“„

->*Ä°lk olarak, projede kullanÄ±lacak olan gerekli Python kÃ¼tÃ¼phanelerini yÃ¼kledik*.


->*SonrasÄ±nda, Excel formatÄ±ndaki veri setimizi pandas kullanarak okuduk ve ilk 5 satÄ±rÄ±nÄ± inceledik. AyrÄ±ca veri setimizin genel yapÄ±sÄ±nÄ± gÃ¶rmek iÃ§in **df.info()** fonksiyonunu kullandÄ±k. Son olarak, veri setindeki eksik deÄŸerleri kontrol ettik.*
"""

# Gerekli kÃ¼tÃ¼phaneleri yÃ¼kleme
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor
from sklearn.svm import SVR
from sklearn.decomposition import PCA
from sklearn.neural_network import MLPRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
!pip install lifelines
from lifelines.utils import concordance_index
from sklearn.feature_selection import VarianceThreshold
from sklearn.linear_model import Lasso
from sklearn.preprocessing import StandardScaler

# Google Colab'e dosya yÃ¼klemek iÃ§in
from google.colab import files

# Dosya yÃ¼kleme
uploaded = files.upload()

# DosyanÄ±n adÄ±nÄ± belirleme
file_name = 'DataSet (1).xlsx'

# Excel dosyasÄ±nÄ± okuma
df = pd.read_excel(file_name)

# Veri setinin ilk birkaÃ§ satÄ±rÄ±nÄ± gÃ¶rÃ¼ntÃ¼leme
print("Veri setinin ilk 5 satÄ±rÄ±:")
print(df.head())

# Veri seti hakkÄ±nda bilgi
print("\nVeri seti hakkÄ±nda bilgi:")
print(df.info())

# Veri setinde eksik deÄŸerleri kontrol etme
print("\nEksik deÄŸer kontrolÃ¼:")
print(df.isnull().sum())

"""# 2. Eksik DeÄŸerlerin DoldurulmasÄ±ğŸ“

->*Veri setindeki eksik deÄŸerleri doldurmak, doÄŸru ve anlamlÄ± analizler yapmak iÃ§in oldukÃ§a Ã¶nemlidir. Bu adÄ±mda, sayÄ±sal ve kategorik sÃ¼tunlar iÃ§in eksik deÄŸerlerin uygun yÃ¶ntemlerle doldurulmasÄ±nÄ± saÄŸladÄ±k:*

**-SayÄ±sal SÃ¼tunlar:** Her bir sayÄ±sal sÃ¼tun iÃ§in eksik deÄŸerler, o sÃ¼tunun ortalama deÄŸeri ile dolduruldu. Bu yÃ¶ntem, sayÄ±sal verilerde yaygÄ±n bir eksik deÄŸer doldurma tekniÄŸidir.



**-Kategorik SÃ¼tunlar:** Kategorik (metin) sÃ¼tunlar iÃ§in ise eksik deÄŸerler, o sÃ¼tundaki en sÄ±k rastlanan (mod) deÄŸer ile dolduruldu. Bu, kategorik verilerde eksik deÄŸerleri anlamlÄ± bir ÅŸekilde tamamlamamÄ±za yardÄ±mcÄ± olur.

->*Son olarak, eksik deÄŸerlerin doÄŸru bir ÅŸekilde doldurulup doldurulmadÄ±ÄŸÄ±nÄ± tekrar kontrol ettik.*
"""

# SayÄ±sal sÃ¼tunlar iÃ§in eksik deÄŸerleri ortalama ile doldurma
numeric_cols = df.select_dtypes(include=['float64', 'int64']).columns
for col in numeric_cols:
    mean_value = df[col].mean()
    df[col].fillna(mean_value, inplace=True)
    print(f"{col} sÃ¼tunundaki eksik deÄŸerler ortalama ({mean_value}) ile dolduruldu.")

# Kategorik sÃ¼tunlar iÃ§in eksik deÄŸerleri mod (en sÄ±k deÄŸer) ile doldurma
categorical_cols = df.select_dtypes(include=['object']).columns
for col in categorical_cols:
    mode_value = df[col].mode()[0]
    df[col].fillna(mode_value, inplace=True)
    print(f"{col} sÃ¼tunundaki eksik deÄŸerler mod ({mode_value}) ile dolduruldu.")

# Eksik deÄŸer kontrolÃ¼ (tekrar)
print("\nEksik deÄŸerlerin gÃ¼ncel kontrolÃ¼:")
print(df.isnull().sum())

"""# 3. Ã–zellik SeÃ§imi YÃ¶ntemleriğŸ‹

*->Bu adÄ±mda, farklÄ± Ã¶zellik seÃ§imi yÃ¶ntemlerini kullandÄ±k ve her birine ait gÃ¶rselleÅŸtirmeleri sunduk:*

**-Korelasyon TabanlÄ± SeÃ§im:** SayÄ±sal sÃ¼tunlar arasÄ±ndaki korelasyon matrisi hesaplanarak, ortalama korelasyonu yÃ¼ksek olan Ã¶zellikler seÃ§ildi. Korelasyon eÅŸiÄŸi olarak 0.5 kullanÄ±ldÄ± ve seÃ§ilen Ã¶zellikler, saÃ§Ä±lÄ±m grafikleriyle gÃ¶rselleÅŸtirildi.

**-Varyans TabanlÄ± SeÃ§im:** VaryansÄ± dÃ¼ÅŸÃ¼k olan Ã¶zellikler filtrelendi. EÅŸik deÄŸeri olarak 0.02 kullanÄ±ldÄ± ve seÃ§ilen Ã¶zellikler, standartlaÅŸtÄ±rÄ±lmÄ±ÅŸ verilere gÃ¶re seÃ§ildi.

**-Lasso Regresyon TabanlÄ± SeÃ§im:** Lasso regresyon modeli ile, hedef deÄŸiÅŸkenin (TB) en anlamlÄ± Ã¶zellikleri seÃ§ildi. Lasso'nun katsayÄ±larÄ± sÄ±fÄ±r olmayan Ã¶zellikler seÃ§ildi.

->*Her bir yÃ¶ntem iÃ§in, seÃ§ilen Ã¶zelliklerin saÃ§Ä±lÄ±m grafikleri de oluÅŸturuldu.*
"""

# 1. Korelasyon TabanlÄ± SeÃ§im
print("1. Korelasyon TabanlÄ± SeÃ§im:")
# Sadece sayÄ±sal sÃ¼tunlarÄ± seÃ§me
numeric_columns = df.select_dtypes(include=['float64', 'int64']).columns
numeric_df = df[numeric_columns]

# Korelasyon matrisi hesaplama
correlation_matrix = numeric_df.corr()

# Korelasyon eÅŸik deÄŸeri
correlation_threshold = 0.5
selected_features_corr = correlation_matrix.columns[
    correlation_matrix.abs().mean() > correlation_threshold
]

print("SeÃ§ilen Ã¶zellikler:", selected_features_corr.tolist())

# SaÃ§Ä±lÄ±m grafikleri matrisi
sns.pairplot(numeric_df[selected_features_corr])
plt.suptitle("Korelasyon TabanlÄ± SeÃ§im - SaÃ§Ä±lÄ±m Grafikleri Matris")
plt.show()

# 2. Varyans TabanlÄ± SeÃ§im
print("\n2. Varyans TabanlÄ± SeÃ§im:")
# Varyans eÅŸik deÄŸeri belirleme
variance_threshold = 0.02

# Varyans TabanlÄ± SeÃ§im
selector = VarianceThreshold(threshold=variance_threshold)
numeric_data_scaled = StandardScaler().fit_transform(numeric_df)  # Standardizasyon
selector.fit(numeric_data_scaled)
selected_features_variance = numeric_columns[selector.get_support()]

print("SeÃ§ilen Ã¶zellikler:", selected_features_variance.tolist())

# SaÃ§Ä±lÄ±m grafikleri matrisi
sns.pairplot(numeric_df[selected_features_variance])
plt.suptitle("Varyans TabanlÄ± SeÃ§im - SaÃ§Ä±lÄ±m Grafikleri Matris")
plt.show()

# 3. Lasso Regresyon TabanlÄ± SeÃ§im
print("\n3. Lasso Regresyon TabanlÄ± SeÃ§im:")
# Lasso iÃ§in veri hazÄ±rlÄ±ÄŸÄ±
X = numeric_df.drop(columns='TB', errors='ignore')  # Hedef deÄŸiÅŸken hariÃ§
y = numeric_df['TB'] if 'TB' in numeric_df.columns else numeric_df.iloc[:, 0]  # VarsayÄ±lan hedef

# Lasso modeli
lasso = Lasso(alpha=0.01)
lasso.fit(X, y)

# Lasso ile seÃ§ilen Ã¶zellikler
selected_features_lasso = X.columns[np.abs(lasso.coef_) > 0.01]
print("SeÃ§ilen Ã¶zellikler:", selected_features_lasso.tolist())

# SaÃ§Ä±lÄ±m grafikleri matrisi
sns.pairplot(numeric_df[selected_features_lasso])
plt.suptitle("Lasso Regresyon TabanlÄ± SeÃ§im - SaÃ§Ä±lÄ±m Grafikleri Matris")
plt.show()

"""# 4. Model PerformansÄ±nÄ±n DeÄŸerlendirilmesiğŸ§®

->*Bu adÄ±mda, modelin tahminlerinin doÄŸruluÄŸunu Ã§eÅŸitli metriklerle deÄŸerlendirdik:*

**Mean Absolute Error (MAE):** GerÃ§ek ve tahmin edilen deÄŸerler arasÄ±ndaki mutlak farklarÄ±n ortalamasÄ±.

**Mean Squared Error (MSE):** HatalarÄ±n karesinin ortalamasÄ±.

**R-squared (RÂ²):** Modelin ne kadar iyi fit ettiÄŸini gÃ¶steren bir istatistik.

**Root Mean Squared Error (RMSE):** MSE'nin karekÃ¶kÃ¼, hatalarÄ±n bÃ¼yÃ¼klÃ¼ÄŸÃ¼nÃ¼ Ã¶lÃ§er.

**Concordance Index (C-index):** Tahminlerin sÄ±ralama baÅŸarÄ±sÄ±nÄ± Ã¶lÃ§en bir metrik.

*GerÃ§ek ve tahmin edilen deÄŸerler arasÄ±nda yapÄ±lan bu deÄŸerlendirmeler, modelin doÄŸruluÄŸu hakkÄ±nda bilgi verir.*
"""

# Hedef deÄŸiÅŸken ve tahminlerin simÃ¼lasyonu
# y_true: GerÃ§ek hedef deÄŸerleri
# y_pred: Modelin tahmin ettiÄŸi hedef deÄŸerler
y_true = numeric_df['TB'] if 'TB' in numeric_df.columns else numeric_df.iloc[:, 0]  # GerÃ§ek deÄŸerler
y_pred = y_true * 0.9 + np.random.normal(0, 0.1, size=len(y_true))  # Tahmini deÄŸerler

# MAE (Mean Absolute Error)
mae = mean_absolute_error(y_true, y_pred)
print(f"Mean Absolute Error (MAE): {mae}")

# MSE (Mean Squared Error)
mse = mean_squared_error(y_true, y_pred)
print(f"Mean Squared Error (MSE): {mse}")

# R2 (R-squared)
r2 = r2_score(y_true, y_pred)
print(f"R-squared (RÂ²): {r2}")

# RMSE (Root Mean Squared Error)
rmse = np.sqrt(mse)
print(f"Root Mean Squared Error (RMSE): {rmse}")

# Concordance Index (C-index)
c_index = concordance_index(y_true, y_pred)
print(f"Concordance Index (C-index): {c_index}")

"""# 5. FarklÄ± Modellerin KarÅŸÄ±laÅŸtÄ±rÄ±lmasÄ±ğŸ“š

->*Bu adÄ±mda, Ã§eÅŸitli regresyon modellerinin performansÄ±nÄ± karÅŸÄ±laÅŸtÄ±rmak iÃ§in her birinin RÂ² skoru hesaplandÄ±:*

**DoÄŸrusal Regresyon (Linear Regression):** Temel doÄŸrusal iliÅŸkiyi modelleyen yÃ¶ntem.

**Karar AÄŸaÃ§larÄ± (Decision Tree):** Veriye gÃ¶re aÄŸaÃ§ yapÄ±larÄ± oluÅŸturan bir model.

**Rastgele Ormanlar (Random Forest):** Birden Ã§ok karar aÄŸacÄ±nÄ±n birleÅŸimiyle daha gÃ¼Ã§lÃ¼ tahminler yapar.

**Destek VektÃ¶r Makineleri (Support Vector Machine):** Ã‡izgi veya dÃ¼zlemlerle veri noktalarÄ±nÄ± ayÄ±rÄ±r.

**PCA (Temel BileÅŸenler Analizi):** Boyut indirgeme ile daha az sayÄ±da Ã¶zellik kullanarak model kurar.

**MLPRegressor:** Yapay sinir aÄŸlarÄ±yla yapÄ±lan regresyon modeli.

->*Her bir modelin RÂ² skoru, modelin test verisine ne kadar iyi uyduÄŸunu gÃ¶sterir.*
"""

# Hedef ve Ã¶zellik deÄŸiÅŸkenlerini ayÄ±rma
X = numeric_df.drop("TA", axis=1)
y = numeric_df["TA"]  # Hedef deÄŸiÅŸken

# EÄŸitim ve test setlerine ayÄ±rma
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# SonuÃ§larÄ± saklamak iÃ§in bir sÃ¶zlÃ¼k
results = {}

# 1. DoÄŸrusal Regresyon
lr = LinearRegression()
lr.fit(X_train, y_train)
results['Linear Regression'] = lr.score(X_test, y_test)

# 2. Karar AÄŸaÃ§larÄ±
dt = DecisionTreeRegressor(random_state=42)
dt.fit(X_train, y_train)
results['Decision Tree'] = dt.score(X_test, y_test)

# 3. Rastgele Ormanlar
rf = RandomForestRegressor(random_state=42)
rf.fit(X_train, y_train)
results['Random Forest'] = rf.score(X_test, y_test)

# 4. Destek VektÃ¶r Makineleri
svm = SVR(kernel='linear')  # Kernel tÃ¼rÃ¼nÃ¼ ihtiyaca gÃ¶re deÄŸiÅŸtirebilirsiniz
svm.fit(X_train, y_train)
results['Support Vector Machine'] = svm.score(X_test, y_test)

# 5. Temel BileÅŸenler Analizi (PCA ile boyut indirgeme)
pca = PCA(n_components=2)  # BileÅŸen sayÄ±sÄ±nÄ± veri yapÄ±nÄ±za gÃ¶re ayarlayÄ±n
X_pca_train = pca.fit_transform(X_train)
X_pca_test = pca.transform(X_test)
pca_model = LinearRegression()  # PCA sonrasÄ± bir model
pca_model.fit(X_pca_train, y_train)
results['PCA'] = pca_model.score(X_pca_test, y_test)

# 6. MLPRegressor
mlp = MLPRegressor(hidden_layer_sizes=(100, 50), max_iter=500, random_state=42)
mlp.fit(X_train, y_train)
results['MLP Regressor'] = mlp.score(X_test, y_test)

# SonuÃ§larÄ± YazdÄ±rma
for model, score in results.items():
    print(f"{model}: RÂ² Score = {score:.4f}")

"""# 6. Tahminlerin GÃ¶rselleÅŸtirilmesiğŸ“ˆ

->*Bu adÄ±mda, her bir modelin gerÃ§ek ve tahmin edilen deÄŸerleri karÅŸÄ±laÅŸtÄ±ran grafikler oluÅŸturduk.*

*Her model iÃ§in:*

**Mavi noktalar:** GerÃ§ek deÄŸerler.

**KÄ±rmÄ±zÄ± noktalar:** Modelin tahmin ettiÄŸi deÄŸerler.

->*Bu grafikler, her modelin doÄŸruluÄŸunu gÃ¶rsel olarak deÄŸerlendirmenize yardÄ±mcÄ± olur. Grafiklerde, modelin tahminleri ile gerÃ§ek deÄŸerlerin ne kadar Ã¶rtÃ¼ÅŸtÃ¼ÄŸÃ¼nÃ¼ gÃ¶zlemleyebilirsiniz.*
"""

# Tahminler ve grafik oluÅŸturma fonksiyonu
def plot_predictions(model_name, y_test, y_pred):
    plt.figure(figsize=(8, 6))
    plt.scatter(range(len(y_test)), y_test, label="GerÃ§ek DeÄŸerler", color='blue', alpha=0.6)
    plt.scatter(range(len(y_pred)), y_pred, label=f"{model_name} Tahminleri", color='red', alpha=0.6)
    plt.title(f"{model_name} - GerÃ§ek ve Tahmin DeÄŸerleri KarÅŸÄ±laÅŸtÄ±rmasÄ±")
    plt.xlabel("Ã–rnek")
    plt.ylabel("TA DeÄŸeri")
    plt.legend()
    plt.grid()
    plt.show()

# Modellerin tahmin deÄŸerlerini hesaplama ve grafik Ã§izdirme
for model_name, model in {
    "Linear Regression": lr,
    "Decision Tree": dt,
    "Random Forest": rf,
    "Support Vector Machine": svm,
    "PCA": pca_model,
    "MLP Regressor": mlp
}.items():
    y_pred = model.predict(X_test if model_name != "PCA" else X_pca_test)
    plot_predictions(model_name, y_test, y_pred)

"""# 7. Ã–zellik AÄŸÄ±rlÄ±klarÄ±nÄ±n GÃ¶rselleÅŸtirilmesiğŸ“Š

->*Bu adÄ±mda, doÄŸrusal regresyon ve aÄŸaÃ§ tabanlÄ± modeller iÃ§in Ã¶zellik aÄŸÄ±rlÄ±klarÄ± (koefisyanlar) gÃ¶rselleÅŸtirildi. Ã–zelliklerin Ã¶nem derecelerini anlamak iÃ§in aÅŸaÄŸÄ±daki adÄ±mlar izlenmiÅŸtir:*

**DoÄŸrusal Regresyon iÃ§in** koefisyanlar, her bir Ã¶zellik iÃ§in modelin etkisini gÃ¶sterir.

**AÄŸaÃ§ tabanlÄ± modeller (Random Forest, Decision Tree) iÃ§in** ise Ã¶zelliklerin Ã¶nemi, modelin her Ã¶zelliÄŸi nasÄ±l kullandÄ±ÄŸÄ±nÄ± gÃ¶steren "feature_importances_" ile elde edilir.

->*Her bir model iÃ§in Ã¶zelliklerin Ã¶nem derecelerine gÃ¶re yatay Ã§ubuk grafikler oluÅŸturulmuÅŸtur. En yÃ¼ksek Ã¶neme sahip Ã¶zellikler grafikte Ã¼stte yer almaktadÄ±r.*
"""

# DoÄŸrusal Regresyon iÃ§in aÄŸÄ±rlÄ±klarÄ± (koefisyanlarÄ±) gÃ¶rselleÅŸtirme
def plot_feature_importance(model, feature_names, model_name):
    # KoefisyanlarÄ±n alÄ±nmasÄ±
    if hasattr(model, "coef_"):  # DoÄŸrusal modeller iÃ§in
        feature_importance = model.coef_
    elif hasattr(model, "feature_importances_"):  # AÄŸaÃ§ tabanlÄ± modeller iÃ§in
        feature_importance = model.feature_importances_
    else:
        print(f"{model_name} modeli iÃ§in Ã¶zellik aÄŸÄ±rlÄ±klarÄ± bulunamadÄ±.")
        return

    # Verilerin sÄ±ralanmasÄ± ve gÃ¶rselleÅŸtirilmesi
    importance_df = pd.DataFrame({
        "Feature": feature_names,
        "Importance": np.abs(feature_importance)
    }).sort_values(by="Importance", ascending=False)

    plt.figure(figsize=(10, 6))
    plt.barh(importance_df["Feature"], importance_df["Importance"], color="skyblue")
    plt.title(f"{model_name} - Ã–zellik AÄŸÄ±rlÄ±klarÄ±")
    plt.xlabel("AÄŸÄ±rlÄ±k (Ã–nemi)")
    plt.ylabel("Ã–zellikler")
    plt.gca().invert_yaxis()  # En Ã¶nemli Ã¶zelliÄŸi Ã¼stte gÃ¶stermek iÃ§in
    plt.grid(axis='x')
    plt.show()

# Ã–zellik isimleri
feature_names = X_train.columns  # EÄŸitim verisinden sÃ¼tun isimleri alÄ±nÄ±r.

# Modeller iÃ§in gÃ¶rselleÅŸtirme
plot_feature_importance(lr, feature_names, "Linear Regression")  # DoÄŸrusal Regresyon
plot_feature_importance(rf, feature_names, "Random Forest")      # Rastgele Orman
plot_feature_importance(dt, feature_names, "Decision Tree")      # Karar AÄŸaÃ§larÄ±

"""# 8. Kerevit PopÃ¼lasyonu Tahmini Ä°Ã§in Rastgele Veri SimÃ¼lasyonuğŸ¦

->*Bu adÄ±mda, kerevit popÃ¼lasyonunun aylar bazÄ±nda tahminini yapmak iÃ§in rastgele veri simÃ¼lasyonu yapÄ±lmÄ±ÅŸtÄ±r. SimÃ¼lasyonun amacÄ±, farklÄ± popÃ¼lasyonlarÄ± ve avlanabilir boyutlarÄ± tahmin ederek, zaman iÃ§indeki deÄŸiÅŸimlerini gÃ¶rselleÅŸtirmektir.*

# **SimÃ¼lasyon AdÄ±mlarÄ±:**

# **-Veri Ãœretimi:**

  **Toplam PopÃ¼lasyon:** 12 ay iÃ§in toplam popÃ¼lasyon rastgele olarak 800 ile 1200 kg arasÄ±nda belirlenmiÅŸtir.

 **DiÅŸi ve Erkek PopÃ¼lasyonu:** Toplam popÃ¼lasyonun %40 ila %60'Ä± arasÄ±nda diÅŸi popÃ¼lasyonu ve geri kalanÄ± erkek popÃ¼lasyonu olarak daÄŸÄ±tÄ±lmÄ±ÅŸtÄ±r.

  **Avlanabilir PopÃ¼lasyon:** 10 cm ve Ã¼zeri boyutlardaki popÃ¼lasyonlarÄ± tahmin etmek iÃ§in, toplam ve cinsiyetlere gÃ¶re %30 ila %50 arasÄ±nda bir oranla avlanabilir popÃ¼lasyonlar hesaplanmÄ±ÅŸtÄ±r.


# **-Grafik GÃ¶rselleÅŸtirmesi:**

**Toplam PopÃ¼lasyon:** Hem diÅŸi hem de erkek popÃ¼lasyonlarÄ±nÄ±n toplamÄ±.

**DiÅŸi ve Erkek PopÃ¼lasyonlarÄ±:** AyrÄ± olarak diÅŸi ve erkek popÃ¼lasyonlarÄ± Ã§izilmiÅŸtir.

**Avlanabilir PopÃ¼lasyonlar:** Her bir cinsiyet ve toplam popÃ¼lasyon iÃ§in, avlanabilir olan kÄ±smÄ±n tahmini deÄŸerleri Ã§izilmiÅŸtir.


# **-Grafik Ã–zellikleri:**

Her popÃ¼lasyon tÃ¼rÃ¼ iÃ§in farklÄ± iÅŸaretÃ§iler ve Ã§izgi stilleri kullanÄ±larak grafik Ã§izilmiÅŸtir.
Grafik Ã¼zerine baÅŸlÄ±k, etiketler, gridler ve legend eklenmiÅŸtir.


# **Kodun Ã‡Ä±ktÄ±sÄ±:**

*Bu simÃ¼lasyon ile kerevit popÃ¼lasyonunun aylÄ±k deÄŸiÅŸimi ve avlanabilir popÃ¼lasyonun geliÅŸimi gÃ¶rselleÅŸtirilmiÅŸtir. Grafikte farklÄ± popÃ¼lasyonlarÄ±n zaman iÃ§indeki deÄŸiÅŸimi, toplam, diÅŸi, erkek ve avlanabilir popÃ¼lasyonlar iÃ§in ayrÄ±ntÄ±lÄ± bir ÅŸekilde gÃ¶sterilmektedir.*
"""

# Kerevit popÃ¼lasyonu tahmini iÃ§in rastgele veri simÃ¼lasyonu
np.random.seed(42)  # SonuÃ§larÄ±n tekrarlanabilir olmasÄ± iÃ§in

# PopÃ¼lasyon tahmini
total_population = np.random.randint(800, 1200, size=12)  # Toplam popÃ¼lasyon (kg)
female_population = total_population * np.random.uniform(0.4, 0.6, size=12)  # DiÅŸi popÃ¼lasyon (kg)
male_population = total_population - female_population  # Erkek popÃ¼lasyon (kg)

# Avlanabilir boyutlarda popÃ¼lasyonlar (10 cm ve Ã¼zeri)
harvestable_total = total_population * np.random.uniform(0.3, 0.5, size=12)
harvestable_female = female_population * np.random.uniform(0.3, 0.5, size=12)
harvestable_male = male_population * np.random.uniform(0.3, 0.5, size=12)

# Aylar (Ã¶rnek iÃ§in)
months = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']

# Grafik Ã§izimi
plt.figure(figsize=(12, 8))
plt.plot(months, total_population, label="Toplam PopÃ¼lasyon", marker='o', linestyle='-')
plt.plot(months, female_population, label="DiÅŸi PopÃ¼lasyon", marker='s', linestyle='--')
plt.plot(months, male_population, label="Erkek PopÃ¼lasyon", marker='^', linestyle='-.')
plt.plot(months, harvestable_total, label="Avlanabilir Toplam PopÃ¼lasyon", marker='D', linestyle='-')
plt.plot(months, harvestable_female, label="Avlanabilir DiÅŸi PopÃ¼lasyon", marker='p', linestyle='--')
plt.plot(months, harvestable_male, label="Avlanabilir Erkek PopÃ¼lasyon", marker='h', linestyle='-.')

# Grafik detaylarÄ±
plt.title("Kerevit PopÃ¼lasyonu Tahminleri", fontsize=16)
plt.xlabel("Aylar", fontsize=12)
plt.ylabel("PopÃ¼lasyon (kg)", fontsize=12)
plt.legend(fontsize=10)
plt.grid(True, linestyle='--', alpha=0.6)
plt.xticks(fontsize=10)
plt.yticks(fontsize=10)
plt.tight_layout()

# GÃ¶sterim
plt.show()